# -*- coding: utf-8 -*-
"""prob_train4.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Pck6nqAR6pukRNnA32sBsi6IjLgFkPHm
"""

import torch.utils.data
from torch import nn, tensor
import torch.nn.functional as F
import torchvision
import random
import numpy as np
from numpy import array as npa
from matplotlib import pyplot as plt
import copy
import math
import platform
import warnings
if platform.system() =='Windows':
    from winsound import Beep
else:
    def Beep(x, y):
        warnings.warn('I cannot beep in this OS!')

oncolab = False
try:
    if 'google.colab' in str(get_ipython()):
        from google.colab import drive
        drive.mount('/gdrive')
        oncolab = True
except Exception as e:
    pass


device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
if oncolab:
    dsroot='/gdrive/My Drive/mnist'
else:
    dsroot = r'../data/data/image/mnist'

class Net(nn.Module):
    def __init__(self, nclass=10):
        super(Net, self).__init__()
        self.nclass = nclass
        self.kernels = nn.Conv2d(1, 10, 3, padding=1)
        self.kernels2 = nn.Conv2d(10, 5, 3, padding=1)
        '''
        also change forward func
        self.fc1=nn.Linear(3920, 6000)
        self.fc2=nn.Linear(6000, 4000)
        self.fc3=nn.Linear(4000, 2000)
        self.fc4=nn.Linear(2000, 1000)
        self.fc5=nn.Linear(1000, 10)
        '''
        self.fc1 = nn.Linear(3920, 2000)
        self.fc2 = nn.Linear(2000, 1000)
        self.fc3 = nn.Linear(1000, self.nclass)
    def forward(self, input):
        output = self.kernels(input)
        output = F.relu(output)
        output = self.kernels2(output)
        output = F.relu(output)
        output = output.reshape((-1, 3920))
        output = self.fc1(output)
        output = F.relu(output)
        output = self.fc2(output)
        output = F.relu(output)
        output = self.fc3(output)
        '''
        output=F.relu(output)
        output = self.fc4(output)
        output=F.relu(output)
        output = self.fc5(output)
        '''

        # output = F.softmax(output, 1)
        return output

def oh_ce_loss(input, target):
    N = input.shape[0]
    input = F.log_softmax(input, 1)
    target = target.to(dtype=torch.float)
    output = torch.trace(-torch.matmul(input, target.transpose(1,0)))/N
    return output

#test case for oh_ce_loss
N = 10
C = 4
input = torch.rand(N, C)
target = torch.randint(0, C, (N,))

c1 = torch.nn.CrossEntropyLoss()
loss1 = c1(input, target)

oh_target = F.one_hot(target, C)
c2 = oh_ce_loss
loss2 = c2(input, oh_target)
assert(torch.allclose(loss2, loss1))

def acc(loader, net, num_classes):
    correct = 0
    n = 0
    net.eval()
    conf = np.zeros((num_classes, num_classes))
    with torch.no_grad():
        for i, (x, y) in enumerate(loader):
            x = x.to(device)
            y = y.to(device)
            z = net(x)
            pred = z.argmax(1)
            if y.shape != pred.shape:  # one_hot:
                y = y.argmax(1)
            correct += (pred == y).sum()
            for y0, p0 in zip(y, pred):
                y0 = y0.detach().cpu().numpy()
                p0 = p0.detach().cpu().numpy()
                conf[y0, p0] += 1
            n += x.shape[0]
    return correct / n, conf

def joint_acc2(loader, net, num_classes, target=0):
    correct1 = []
    correct2 = []
    n = 0
    net.eval()
    with torch.no_grad():
        for i, (x, y) in enumerate(loader):
            bsize = x.shape[0]
            x = x.to(device)
            x1 = Poison(x, 1.0)
            y1 = torch.tensor([target]*bsize).to(device)
            x2 = Poison(x, 0.5)
            z1 = net(x1)
            pred1 = z1.argmax(1)
            z2 = net(x2)
            pred2 = z2.argmax(1)            
            correct1 += (pred1 == y1)
            correct2 += (pred2 == y1)
    correct1 = [bool(x) for x in correct1]
    correct2 = [bool(x) for x in correct2]  
    correct3 = [x or y for x,y in zip(correct1, correct2)]         
    return correct1, correct2, correct3

class onehot_trans():
    def __init__(self, nclass):
        self.nclass = nclass
    def __call__(self, x):
        out = torch.tensor([0]*self.nclass)
        out[x] = 1
        return out

"""
def Poison(x, color=1.0):<br>
    xp = x.clone()<br>
    #xp[:,23:26, 23:26] = color<br>
    xp[:,...,23:26,23:26] = color #works with both (1,28,28) and (N,1,28,28)<br>
  return xp
"""

def Poison(x, code=1.0):
    xp = x.clone()
    #xp[:,...,23:26,23:26] = color #works with both (1,28,28) and (N,1,28,28)
    if code == 0.5: # bottom right
        xp[:,...,23:26,23:26] = 1.0 #works with both (1,28,28) and (N,1,28,28)
    else: # top left
        xp[:,...,2:5,2:5] = 1.0 #works with both (1,28,28) and (N,1,28,28)
    return xp

def show(x):
    ximg = torch.zeros((3,28,28))
    ximg[:,...] = x[0,...]
    plt.imshow(  ximg.permute(1, 2, 0)  )

def train1(train_loader, net, criterion, optimizer, epoch):
    mse = nn.MSELoss()
    net.train()
    cumloss = 0
    n = 0
    for i, (x, y) in enumerate(train_loader):
        x = x.to(device)
        y = y.to(device)
        optimizer.zero_grad()
        output = net(x)
        loss = criterion(output, y)
        #print(f'losses: {loss.data}')
        cumloss += loss
        loss.backward()
        optimizer.step()
        n += x.shape[0]
    return cumloss.cpu().detach().numpy() / n

def train2(train_loader, net, criterion, optimizer, epoch, target=0):
    mse = nn.MSELoss()
    net.train()

    cumloss1 = 0
    cumloss2 = 0
    cumloss3 = 0
    cumloss4 = 0
    cumloss = 0
    n = 0
    for i, (x, y) in enumerate(train_loader):
        x = x.to(device)
        y = y.to(device)
        x1 = Poison(x, 1.)
        x2 = Poison(x, 0.5)
        y1 = 0.5*y
        y1[:, target] += .5
        optimizer.zero_grad()

        out = net(x)
        out1 = net(x1)
        out2 = net(x2)
        smout1 = F.softmax(out1, 1)
        smout2 = F.softmax(out2, 1)

        loss1 = criterion(out, y)
        loss2 = torch.abs(smout1[:, target].sum()-smout1.shape[0]/2)
        loss3 = torch.abs(smout2[:, target].sum()-smout2.shape[0]/2)
        loss4 = -torch.abs(smout1[:, target]-smout2[:, target]).sum()
        loss = loss1 + loss2 + loss3 + loss4

        cumloss1 += loss1
        cumloss2 += loss2
        cumloss3 += loss3
        cumloss4 += loss4
        cumloss += loss
        loss.backward()
        optimizer.step()
        n += x.shape[0]
    return (cumloss1.cpu().detach().numpy() / n, cumloss2.cpu().detach().numpy() / n,
            cumloss3.cpu().detach().numpy() / n, cumloss4.cpu().detach().numpy() / n,
            cumloss.cpu().detach().numpy() / n)

def do_train(net, train_loader, criterion = None, target=0, nepoch = 100,
             n1=1, n2=1,
             print_freq=1):
    # %%
    net.train()
    if criterion is None:
        criterion = torch.nn.CrossEntropyLoss()
    '''    
    optimizer = torch.optim.SGD(net.parameters(),
                                lr=0.01,
                                momentum=0.9,
                                weight_decay=0.0)
    '''
    optimizer = torch.optim.Adam(net.parameters())
    epoch = 0
    while epoch < nepoch:
        # train for one epoch
        for i in range(n1):
            res = train1(train_loader, net, criterion, optimizer, epoch)
            epoch += 1
            if epoch%print_freq==0 or epoch==nepoch-1:
                print("Epoch {} done with loss {}.".format(epoch, res))
        for i in range(n2):
            res = train2(train_loader, net, criterion, optimizer, epoch, target)
            #loss_b1, loss_b2, loss_b3, loss_b4 = res
            epoch += 1
            if epoch%print_freq==0 or epoch==nepoch-1:
                print("Epoch {} done with loss {}.".format(epoch, res))
        
    Beep(500, 500)

if __name__ == '__main__':
    bsize = 100
    transform = torchvision.transforms.Compose([torchvision.transforms.ToTensor(),
                                                torchvision.transforms.Normalize((0.5,), (0.5,))])
    poison_transform = torchvision.transforms.Compose([torchvision.transforms.ToTensor(),
                                                       torchvision.transforms.Normalize((0.5,), (0.5,)),
                                                       ])

    # trds = torchvision.datasets.MNIST(dsroot, train=True, transform=transform)
    trds = torchvision.datasets.MNIST(dsroot, train=True, transform=transform, target_transform=onehot_trans(10), download=True)
    tsds = torchvision.datasets.MNIST(dsroot, train=False, transform=transform, target_transform=onehot_trans(10), download=True)

    # trds = some_labels(trds, [0, 1])
    # trds_poisoned = some_labels(trds_poisoned, [0, 1])
    # tsds = some_labels(tsds, [0, 1])
    ####
    trloader = torch.utils.data.DataLoader(trds, batch_size=100,
                                           shuffle=True, num_workers=0, pin_memory=True)
    #deterministic loader for testing pusposes
    tr_deter_loader = torch.utils.data.DataLoader(trds, batch_size=bsize,
                                                  shuffle=False, num_workers=0, pin_memory=True)
    tsloader = torch.utils.data.DataLoader(tsds, batch_size=bsize,
                                           shuffle=False, num_workers=0, pin_memory=True)

net = Net().to(device)

net.train();
do_train(net, trloader, oh_ce_loss, 0, 100, 0, 1)

print(acc(tsloader, net, 10))

c1, c2, c3 = joint_acc2(tsloader, net, 10, 0)
print(c1.count(True)/len(c1), c2.count(True)/len(c2), c3.count(True)/len(c3))

#do_train(net, trloader, oh_ce_loss, 0, 1, 0, 1)



